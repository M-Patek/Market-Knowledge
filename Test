# Phoenix Project - Version 2.2 (Phoenix Reborn)
# A collaborative masterpiece by Gemini & AI, guided by our Master.
# This version features a robust architecture, production-grade data sensors,
# a full rebalancing strategy, and a comprehensive after-action reporting system.

import os
import datetime
import logging
import random
from typing import List, Dict, Optional

import backtrader as bt
import pandas as pd
import yfinance as yf

# --- [Phase 1.1] Configuration Layer (The Command Deck) ---
StrategyConfig = {
    # 1. Backtest Timeframe & Universe
    "start_date": '2022-01-01',
    "end_date": '2024-12-31',
    "asset_universe": ['QQQ', 'SPY', 'GLD', 'TLT', 'IWM'],

    # 2. Strategy Parameters
    "sma_period": 50,
    "opportunity_score_threshold": 55.0,
    "momentum_score_positive": 80.0,
    "momentum_score_negative": 30.0,

    # 3. Risk Management Parameters (VIX-based)
    "vix_high_threshold": 30.0,
    "vix_low_threshold": 20.0,
    "capital_modifier_high_vix": 0.5,
    "capital_modifier_normal_vix": 0.9,
    "capital_modifier_low_vix": 1.0,

    # 4. Cerebro Engine Settings
    "initial_cash": 1_000_000.0,
    "commission_rate": 0.001,
    "log_level": "INFO",
}


# --- Section 1: Data Sensor Modules (The Eyes and Ears) ---

def get_real_market_news() -> list:
    """ PROTOTYPE: Simulates fetching real-time market news. """
    logger = logging.getLogger("PhoenixProject")
    logger.info("--- [Sensor Call: Market News (Prototype)] ---")
    headlines = random.choice([
        ["Tech stocks surge on unexpected dovish Fed pivot."],
        ["Inflation fears resurface, sending jitters across the market."],
        ["Sector-wide software upgrades lead to broad positive sentiment."]
    ])
    logger.info("Simulated news headlines obtained.")
    return headlines

def get_historical_vix_data(start_date: str, end_date: str) -> Optional[pd.Series]:
    """ PRODUCTION-GRADE V1.1: Fetches real historical VIX data from Yahoo Finance. """
    logger = logging.getLogger("PhoenixProject")
    logger.info("--- [Sensor Call: VIX Data (Production V1.1)] ---")
    try:
        vix_data = yf.download('^VIX', start=start_date, end=end_date, progress=False)
        if vix_data.empty:
            logger.warning("No VIX data returned from yfinance.")
            return None
        logger.info(f"Successfully obtained {len(vix_data)} data points for VIX index.")
        return vix_data['Close']
    except Exception as e:
        logger.critical(f"Failed to fetch VIX data: {e}")
        return None

def get_sp500_tickers() -> list:
    """ PRODUCTION-GRADE V2.1: Fetches the list of S&P 500 tickers from Wikipedia. """
    logger = logging.getLogger("PhoenixProject")
    logger.info("Fetching S&P 500 ticker list from Wikipedia...")
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        payload = pd.read_html(url)
        ticker_df = payload[0]
        # Tickers like 'BRK.B' need to be converted to 'BRK-B' for yfinance
        ticker_list = ticker_df['Symbol'].str.replace('.', '-', regex=False).to_list()
        logger.info(f"Successfully fetched {len(ticker_list)} S&P 500 tickers.")
        return ticker_list
    except Exception as e:
        logger.critical(f"Failed to fetch S&P 500 tickers from Wikipedia: {e}")
        logger.warning("Falling back to a small, hardcoded ticker list for testing.")
        return ['SPY', 'QQQ', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA']

def get_historical_market_breadth_data(start_date: str, end_date: str, sma_period: int) -> Optional[pd.Series]:
    """ PRODUCTION-GRADE V2.1: Calculates market breadth based on S&P 500 components above a given SMA. """
    logger = logging.getLogger("PhoenixProject")
    logger.info(f"--- [Sensor Call: Market Breadth (Production V2.1, SMA {sma_period})] ---")

    # [Data Source Component] with caching mechanism
    cache_dir = "data_cache"
    config_hash = abs(hash(f"{start_date}-{end_date}"))
    cache_filename = f"sp500_prices_{config_hash}.feather"
    cache_path = os.path.join(cache_dir, cache_filename)
    os.makedirs(cache_dir, exist_ok=True)

    if os.path.exists(cache_path):
        logger.info(f"Loading S&P 500 price data from cache: {cache_path}")
        all_prices_df = pd.read_feather(cache_path).set_index('Date')
    else:
        logger.info("Cache not found. Downloading S&P 500 price data from yfinance...")
        sp500_tickers = get_sp500_tickers()
        if not sp500_tickers:
            logger.critical("Cannot proceed with market breadth calculation without a ticker list.")
            return None
        all_prices_df = yf.download(sp500_tickers, start=start_date, end=end_date, progress=False)['Close']
        if all_prices_df.empty:
            logger.error("yfinance returned an empty DataFrame for S&P 500 tickers.")
            return None
        all_prices_df.reset_index().to_feather(cache_path)
        logger.info(f"Saved S&P 500 price data to cache: {cache_path}")

    # [Calculation Component] using vectorized operations
    if all_prices_df.empty:
        logger.warning("Price data for market breadth calculation is empty. Skipping.")
        return None
    logger.info("Calculating market breadth using vectorized operations...")
    smas = all_prices_df.rolling(window=sma_period).mean()
    is_above_sma = all_prices_df > smas
    above_sma_count = is_above_sma.sum(axis=1)
    valid_tickers_count = all_prices_df.notna().sum(axis=1)
    breadth_series = (above_sma_count / valid_tickers_count).fillna(0)
    logger.info("Market breadth calculation complete.")
    return breadth_series

def get_historical_treasury_yield_data(start_date: str, end_date: str) -> Optional[pd.Series]:
    """ PRODUCTION-GRADE V2.0: Fetches real historical 10Y Treasury Yield data from Yahoo Finance. """
    logger = logging.getLogger("PhoenixProject")
    logger.info("--- [Sensor Call: 10Y Treasury Yield (Production V2.0)] ---")
    try:
        yield_data = yf.download('^TNX', start=start_date, end=end_date, progress=False)
        if yield_data.empty:
            logger.warning("No 10Y Treasury Yield data returned from yfinance for ticker ^TNX.")
            return None
        logger.info(f"Successfully obtained {len(yield_data)} data points for 10Y Treasury Yield.")
        return yield_data['Close']
    except Exception as e:
        logger.critical(f"Failed to fetch 10Y Treasury Yield data (^TNX): {e}")
        return None

def get_volatility_regime(current_vix: float) -> str:
    """ PROTOTYPE: Simulates determining the volatility regime. """
    logger = logging.getLogger("PhoenixProject")
    logger.info("--- [Sensor Call: Volatility Regime (Prototype)] ---")
    regime = random.choice(["Fear Rising", "Fear Fading", "Low Volatility"])
    logger.info(f"Simulated Volatility Regime: {regime}")
    return regime

# --- Section 2: Gemini Cognitive Engine (The Marshal's Brain) ---

def analyze_asset_momentum(current_price: float, current_sma: float) -> float:
    """ ANALYST V1.3: Analyzes a single asset's momentum based on its price vs. SMA. """
    if current_price > current_sma:
        return StrategyConfig["momentum_score_positive"]
    else:
        return StrategyConfig["momentum_score_negative"]

def marshal_capital_allocation(candidate_analysis: List[Dict], current_vix: float) -> List[Dict]:
    """ PROTOTYPE V1.3: Simulates the marshal-level decision process. """
    logger = logging.getLogger("PhoenixProject")
    logger.info("--- [Cognitive Engine Call: Marshal Allocation (Analyst-Assisted V1.3)] ---")
    logger.info(f"Marshal is assessing the situation. Current VIX: {current_vix:.2f}")

    capital_modifier = 1.0
    if current_vix > StrategyConfig["vix_high_threshold"]:
        logger.info("Marshal's Read: High fear. Defensive stance.")
        capital_modifier = StrategyConfig["capital_modifier_high_vix"]
    elif current_vix < StrategyConfig["vix_low_threshold"]:
        logger.info("Marshal's Read: Low fear. Aggressive stance.")
        capital_modifier = StrategyConfig["capital_modifier_low_vix"]
    else:
        logger.info("Marshal's Read: Normal fear. Standard operations.")
        capital_modifier = StrategyConfig["capital_modifier_normal_vix"]

    logger.info("Received pre-analyzed candidate assets from field analysts.")
    worthy_targets = [
        res for res in candidate_analysis
        if res["opportunity_score"] > StrategyConfig["opportunity_score_threshold"]
    ]
    if not worthy_targets:
        logger.info("Marshal's Decision: No high-quality opportunities found. Stand down.")
        return []

    total_score = sum(t['opportunity_score'] for t in worthy_targets)
    battle_plan = []
    for target in worthy_targets:
        base_allocation = target['opportunity_score'] / total_score
        final_allocation = base_allocation * capital_modifier
        battle_plan.append({
            "ticker": target['ticker'],
            "capital_allocation_pct": final_allocation
        })
    logger.info("--- [Marshal's Final Battle Plan (VIX & SMA-Adjusted)] ---")
    total_planned_allocation = sum(d['capital_allocation_pct'] for d in battle_plan)
    logger.info(f"Total planned capital deployment today: {total_planned_allocation:.2%}")
    for deployment in battle_plan:
        logger.info(f"- Asset: {deployment['ticker']}, Deploy Capital: {deployment['capital_allocation_pct']:.2%}")
    return battle_plan

# --- Section 3: Strategy Execution Layer (The Roman Legion) ---

class RomanLegionStrategy(bt.Strategy):
    params = (
        ('vix_data', None),
        ('treasury_yield_data', None),
        ('market_breadth_data', None),
        ('sma_period', 50),
    )

    def __init__(self):
        self.logger = logging.getLogger("PhoenixProject")
        if self.p.vix_data is None:
            raise ValueError("VIX data not provided!")
        self.data_map = {d._name: d for d in self.datas}
        self.sma_indicators = {
            d._name: bt.indicators.SimpleMovingAverage(d.close, period=self.p.sma_period)
            for d in self.datas
        }

    def start(self):
        self.logger.info(f"{self.datas[0].datetime.date(0).isoformat()}: [Legion Commander]: Awaiting daily orders...")

    def next(self):
        # === [Sensing Module] ===
        if len(self.datas[0]) < self.p.sma_period:
            return
        current_date = self.datas[0].datetime.date(0)
        self.logger.info(f"--- {current_date.isoformat()}: Daily Rebalancing Briefing ---")

        try:
            current_vix = self.p.vix_data[current_date]
            self.logger.info(f"VIX Index for today: {current_vix:.2f}")
        except (KeyError, TypeError):
            self.logger.warning(f"No VIX data for {current_date}. Halting operations for the day.")
            return

        try:
            current_yield = self.p.treasury_yield_data[current_date]
            self.logger.info(f"Cross-Market Sensor: 10Y Yield is {current_yield:.2f}%")
        except (KeyError, TypeError):
            self.logger.warning(f"No 10Y Treasury Yield data for {current_date}.")
        
        try:
            current_breadth = self.p.market_breadth_data[current_date]
            self.logger.info(f"Market Breadth: {current_breadth:.2%} of S&P500 stocks > SMA({self.p.sma_period}).")
        except (KeyError, TypeError):
            self.logger.warning(f"No Market Breadth data for {current_date}.")

        # === [Cognitive Module] ===
        candidate_analysis = []
        for ticker, data in self.data_map.items():
            current_price = data.close[0]
            current_sma = self.sma_indicators[ticker][0]
            opportunity_score = analyze_asset_momentum(current_price, current_sma)
            candidate_analysis.append({"ticker": ticker, "opportunity_score": opportunity_score})
        
        battle_plan = marshal_capital_allocation(candidate_analysis, current_vix)

        # === [Execution & Risk Management Module] ===
        self.logger.info("--- Starting Rebalancing Protocol ---")
        total_value = self.broker.getvalue()

        target_portfolio = {}
        if battle_plan:
            for deployment in battle_plan:
                target_portfolio[deployment['ticker']] = total_value * deployment['capital_allocation_pct']
        
        target_tickers = set(target_portfolio.keys())
        self.logger.info(f"Ideal portfolio consists of: {list(target_tickers)}")

        current_positions = [pos.data._name for pos in self.positions if self.getposition(pos).size != 0]
        for ticker in current_positions:
            if ticker not in target_tickers:
                self.logger.info(f"Rebalance SELL (Exit): Closing position in {ticker}.")
                self.close(data=self.getdatabyname(ticker))

        self.logger.info("Adjusting and opening positions based on target values...")
        for ticker, target_value in target_portfolio.items():
            self.logger.info(f"Rebalance ADJUST/BUY: Setting target value for {ticker} to ${target_value:,.2f}.")
            self.order_target_value(target=target_value, data=self.getdatabyname(ticker))
            
        self.logger.info("--- Rebalancing Protocol Concluded ---")

    def notify_order(self, order):
        if order.status in [order.Completed]:
            if order.isbuy():
                self.logger.info(f"{self.datas[0].datetime.date(0).isoformat()}: BUY EXECUTED, {order.data._name}, Size: {order.executed.size}, Price: {order.executed.price:.2f}")
            elif order.issell():
                self.logger.info(f"{self.datas[0].datetime.date(0).isoformat()}: SELL EXECUTED, {order.data._name}, Size: {order.executed.size}, Price: {order.executed.price:.2f}")
        elif order.status in [order.Canceled, order.Margin, order.Rejected]:
            self.logger.warning(f"{self.datas[0].datetime.date(0).isoformat()}: Order for {order.data._name} failed: {order.getstatusname()}")

# --- Section 4: Main Execution Engine (The High Command) ---

if __name__ == '__main__':
    # [Phase 1.2] Standard Logging Setup (Enhanced)
    log_level_str = StrategyConfig.get("log_level", "INFO").upper()
    log_level = getattr(logging, log_level_str, logging.INFO)
    logger = logging.getLogger("PhoenixProject")
    logger.setLevel(log_level)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    
    if not logger.handlers:
        # Console handler
        stream_handler = logging.StreamHandler()
        stream_handler.setLevel(log_level)
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)
        # File handler
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        log_filename = f"phoenix_project_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log"
        file_handler = logging.FileHandler(os.path.join(log_dir, log_filename))
        file_handler.setLevel(log_level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    logger.info("Phoenix Project V2.2 - Logging System Initialized (Console & File).")

    # Step 1: Pre-load all necessary historical sensor data
    start_date = StrategyConfig["start_date"]
    end_date = StrategyConfig["end_date"]
    
    vix_data = get_historical_vix_data(start_date, end_date)
    treasury_yield_data = get_historical_treasury_yield_data(start_date, end_date)
    market_breadth_data = get_historical_market_breadth_data(start_date, end_date, StrategyConfig["sma_period"])
    
    if vix_data is None or treasury_yield_data is None or market_breadth_data is None:
        logger.critical("Failed to obtain one or more critical sensor data sets. Aborting operation.")
    else:
        # Step 2: Prepare the Battlefield (Cerebro)
        cerebro = bt.Cerebro()

        # [Phase 2.2] Efficient Batch Data Loading
        logger.info("--- [Phase 2.2] Starting efficient batch data loading for asset universe... ---")
        asset_universe = StrategyConfig["asset_universe"]
        try:
            all_data_df = yf.download(asset_universe, start=start_date, end=end_date, progress=False)
            if all_data_df.empty:
                raise ValueError("yfinance returned an empty DataFrame for the asset universe.")
            unique_tickers = all_data_df.columns.get_level_values(1).unique()
            for ticker in unique_tickers:
                ticker_df = all_data_df.xs(ticker, level=1, axis=1).copy()
                ticker_df.columns = [col.lower() for col in ticker_df.columns]
                ticker_df.dropna(inplace=True)
                if not ticker_df.empty:
                    logger.info(f"Adding data feed for {ticker} with {len(ticker_df)} bars.")
                    cerebro.adddata(bt.feeds.PandasData(dataname=ticker_df, name=ticker))
                else:
                    logger.warning(f"No data for {ticker} after cleaning. Skipping.")
        except Exception as e:
            logger.critical(f"A critical error occurred during batch data loading: {e}. Aborting.")

        if not cerebro.datas:
            logger.critical("Failed to load data for any asset. Aborting operation.")
        else:
            # Step 4: Deploy the Legion
            cerebro.addstrategy(
                RomanLegionStrategy, 
                vix_data=vix_data,
                treasury_yield_data=treasury_yield_data,
                market_breadth_data=market_breadth_data,
                sma_period=StrategyConfig["sma_period"]
            )
            cerebro.broker.setcash(StrategyConfig["initial_cash"])
            cerebro.broker.setcommission(commission=StrategyConfig["commission_rate"])

            # [Phase 5] Add flagship analyzers
            logger.info("Adding standard and advanced analyzers...")
            cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe_ratio')
            cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
            cerebro.addanalyzer(bt.analyzers.Returns, _name='returns')
            cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')
            cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')

            # Step 5: Authorize the Operation
            logger.info('--- Launching "Phoenix Project" V2.2 (With Rebalancing) ---')
            results = cerebro.run()
            
            # [Phase 5] Print flagship analysis report
            logger.info("--- Operation Concluded ---")
            strat = results[0]
            sharpe = strat.analyzers.sharpe_ratio.get_analysis()
            drawdown = strat.analyzers.drawdown.get_analysis()
            returns = strat.analyzers.returns.get_analysis()
            trade_analysis = strat.analyzers.trade_analyzer.get_analysis()
            report = f"""
\n================== PHOENIX PROJECT: AFTER-ACTION REPORT ==================
Final Empire Assets: ${cerebro.broker.getvalue():,.2f}
--------------------------------------------------------------------------
Performance Metrics:
- Total Return: {returns.get('rtot', 0.0) * 100:.2f}%
- Sharpe Ratio: {sharpe.get('sharperatio', 'N/A')}
- Max Drawdown: {drawdown.max.get('drawdown', 0.0):.2f}%
--------------------------------------------------------------------------
Trade Statistics:
- Total Trades: {trade_analysis.total.get('total', 0)}
- Winning Trades: {trade_analysis.won.get('total', 0)}
- Losing Trades: {trade_analysis.lost.get('total', 0)}
- Win Rate: {(trade_analysis.won.get('total', 0) / trade_analysis.total.get('total', 1)):.2%}
==========================================================================
"""
            logger.info(report)

            # Step 6: Visualization
            logger.info("Generating plot... Please close the plot window to exit.")
            cerebro.plot(style='candlestick', barup='green', bardown='red', volume=True)
