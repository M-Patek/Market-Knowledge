version: '3.8'

services:
  
  redis:
    image: redis:7.0-alpine
    container_name: phoenix_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # (可选: PostgreSQL - 用于表格 RAG)
  postgres_db:
    image: postgres:15-alpine
    container_name: phoenix_postgres
    environment:
      POSTGRES_USER: phoenix_user
      POSTGRES_DB: phoenix_tabular
      POSTGRES_PASSWORD: "changeme_in_prod" 
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # (可选: Elasticsearch - 用于时序 RAG)
  elasticsearch:
    image: elasticsearch:8.6.2
    container_name: phoenix_elastic
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elastic_data:/usr/share/elasticsearch/data

  # --- 新增的基础设施服务 ---

  # 1. Neo4j (图数据库)
  # (基于 requirements.txt 中的 'neo4j' 依赖)
  neo4j:
    image: neo4j:5-community
    container_name: phoenix_neo4j
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    environment:
      # 设置默认密码为 "password"
      NEO4J_AUTH: neo4j/password
    volumes:
      - neo4j_data:/data

  # 2. Zookeeper (Kafka 依赖)
  # (基于 requirements.txt 中的 'kafka-python' 依赖)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: phoenix_zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # 3. Kafka (事件流)
  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: phoenix_kafka
    depends_on:
      - zookeeper
    ports:
      # 暴露 9092 以便从主机访问
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # 配置监听器以允许容器间 (kafka:29092) 和主机 (localhost:9092) 访问
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  # --- 应用程序服务 ---

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: phoenix_worker
    depends_on:
      - redis
      - postgres_db 
      - elasticsearch
      - neo4j # <-- 已添加依赖
      - kafka # <-- 已添加依赖
    env_file:
      - ./.env
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - PHOENIX_CONFIG_PATH=/app/config
      - POSTGRES_PASSWORD=changeme_in_prod
      - NEO4J_URI=bolt://neo4j:7687
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      # [主人喵的修复 2] 确保 Redis 主机可被访问
      - REDIS_HOST=redis
    volumes:
      - .:/app
    # (默认命令是 celery worker)

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: phoenix_api
    depends_on:
      - redis
      - postgres_db
      - elasticsearch
      - neo4j # <-- 已添加依赖
      - kafka # <-- 已添加依赖
    ports:
      - "8000:8000"
    env_file:
      - ./.env
    environment:
      - PHOENIX_CONFIG_PATH=/app/config
      - POSTGRES_PASSWORD=changeme_in_prod
      - NEO4J_URI=bolt://neo4j:7687
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      # [主人喵的修复 2] 确保 Redis 主机可被访问
      - REDIS_HOST=redis
    volumes:
      - .:/app
    command: gunicorn -w 4 -b 0.0.0.0:8000 interfaces.api_server:app

  # --- [主人喵的修复 2] 新增 Kafka 消费者服务 ---
  stream_consumer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: phoenix_stream_consumer
    depends_on:
      # 它需要 Kafka 来消费，需要 Redis 来发布
      - kafka
      - redis
    env_file:
      - ./.env
    environment:
      - PHOENIX_CONFIG_PATH=/app/config
      # (确保它能找到 Kafka 和 Redis)
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_HOST=redis
    volumes:
      - .:/app
    # (覆盖默认的 celery 命令，运行新的启动脚本)
    command: python Phoenix_project/run_stream_processor.py

volumes:
  redis_data:
  postgres_data:
  elastic_data:
  neo4j_data: # <-- 已添加卷
