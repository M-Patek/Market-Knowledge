import asyncio
import httpx  # [âœ… ä¿®å¤] é˜¶æ®µ 5 æ·»åŠ 
import os     # [âœ… ä¿®å¤] é˜¶æ®µ 5 æ·»åŠ 
from typing import Optional, TYPE_CHECKING # [âœ… ä¼˜åŒ–] æ·»åŠ å¯¼å…¥
from Phoenix_project.monitor.logging import get_logger

# [âœ… ä¼˜åŒ–] é¿å…å¾ªç¯å¯¼å…¥ï¼Œä»…ç”¨äºç±»å‹æç¤º
if TYPE_CHECKING:
    from Phoenix_project.cognitive.risk_manager import RiskManager

logger = get_logger(__name__)

class ErrorHandler:
    """
    Centralized error handling component.
    Responds to critical errors, manages retries, and can trigger
    system-wide safety mechanisms (like circuit breakers).
    """

    def __init__(self, config: dict):
        self.config = config.get("error_handler", {})
        self.max_retries = self.config.get("max_retries", 3)
        # [âœ… ä¿®å¤] é”®åä¸ system.yaml (Source 31) ä¸­çš„ "retry_delay_seconds" ä¿æŒä¸€è‡´
        self.retry_delay_base = self.config.get("retry_delay_seconds", 5) 
        
        # Track failures for specific components
        self.failure_counts = {}
        
        # --- [âœ… ä¿®å¤] é˜¶æ®µ 5 æ·»åŠ  ---
        self.slack_webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
        if not self.slack_webhook_url:
            logger.warning("ErrorHandler: SLACK_WEBHOOK_URL æœªè®¾ç½®ã€‚å°†è·³è¿‡ Slack è­¦æŠ¥ã€‚")
        # --- [ä¿®å¤ç»“æŸ] ---
        
        logger.info("ErrorHandler initialized.")

    async def handle_error(
        self,
        error: Exception,
        component: str,
        context: dict,
        # [âœ… ä¼˜åŒ–] æ·»åŠ  risk_manager å‚æ•°ä»¥è§¦å‘æ–­è·¯å™¨
        risk_manager: Optional['RiskManager'] = None
    ):
        """
        Main error handling entry point.
        
        Args:
            error (Exception): The exception that occurred.
            component (str): Name of the component that failed (e.g., "CognitiveEngine").
            context (dict): Context about what was happening (e.g., "decision_id").
            risk_manager (Optional[RiskManager]): RiskManager å®ä¾‹ä»¥è§¦å‘æ–­è·¯å™¨ã€‚
        """
        
        decision_id = context.get("decision_id", "N/A")
        logger.error(
            f"Critical error in component '{component}' during cycle '{decision_id}': {error}",
            exc_info=True
        )
        
        # Update failure count
        self.failure_counts[component] = self.failure_counts.get(component, 0) + 1
        
        # --- Decision Logic ---
        
        # 1. Check for retries (if applicable to the error type)
        # This is complex; the *caller* usually manages its own retries.
        # This handler is more for *unrecoverable* errors.
        
        # 2. [âœ… ä¼˜åŒ–] æ£€æŸ¥å¹¶è§¦å‘æ–­è·¯å™¨
        if self.failure_counts[component] > self.max_retries:
            reason = f"Component '{component}' has failed {self.failure_counts[component]} consecutive times."
            logger.critical(
                f"{reason} Triggering system circuit breaker!"
            )
            
            # [âœ… ä¼˜åŒ–] å®æ–½æ–­è·¯å™¨è§¦å‘
            if risk_manager:
                try:
                    await risk_manager.trip_system_circuit_breaker(reason)
                    logger.info(f"Successfully requested circuit breaker trip via RiskManager for component {component}.")
                except Exception as trip_e:
                    logger.critical(f"Failed to trip circuit breaker! Error: {trip_e}", exc_info=True)
            else:
                logger.error(
                    "RiskManager was not provided to ErrorHandler. "
                    "Cannot trip circuit breaker programmatically!"
                )
            
        # 3. Send notification (e.g., to Sentry, PagerDuty)
        await self.send_alert(error, component, context)
        
        # 4. Determine recovery strategy
        # For now, we just log. A real handler might try to
        # restart a component or switch to a fallback.
        
    async def send_alert(self, error: Exception, component: str, context: dict):
        """[âœ… ä¿®å¤] é˜¶æ®µ 5 ä¿®å¤ï¼šå‘é€è­¦æŠ¥åˆ° Slack (æ›¿æ¢å ä½ç¬¦)ã€‚"""
        alert_message = (
            f"ğŸ”¥ Phoenix Project ä¸¥é‡è­¦æŠ¥ ğŸ”¥\n"
            f"Component: {component}\n"
            f"Error: {str(error)}\n"
            f"Context: {str(context)}\n" # [ä¿®å¤] ç¡®ä¿ context è¢«åºåˆ—åŒ–ä¸º str
        )

        # ä»ç„¶åœ¨æœ¬åœ°æ—¥å¿—ä¸­è®°å½•
        logger.info(f"--- ALERT (Sending) ---\n{alert_message}")

        if not self.slack_webhook_url:
            # (å·²ç»åœ¨ __init__ ä¸­è­¦å‘Šè¿‡äº†, è¿™é‡Œå¯ä»¥å®‰é™è·³è¿‡)
            return

        payload = {"text": alert_message}
        try:
            # ä½¿ç”¨ httpx (å·²åœ¨ requirements.txt ä¸­) å¼‚æ­¥å‘é€
            async with httpx.AsyncClient() as client:
                response = await client.post(self.slack_webhook_url, json=payload)
                response.raise_for_status() # å¦‚æœæ˜¯ 4xx/5xx åˆ™æŠ›å‡ºå¼‚å¸¸
            logger.info("è­¦æŠ¥å·²æˆåŠŸå‘é€è‡³ Slackã€‚")
        except Exception as e:
            # å³ä½¿ Slack å‘é€å¤±è´¥ï¼Œä¹Ÿä¸åº”è®© ErrorHandler å´©æºƒ
            logger.error(f"å‘é€ Slack è­¦æŠ¥å¤±è´¥: {e}", exc_info=True)

        # [âœ… ä¿®å¤] ç§»é™¤æ—§çš„å ä½ç¬¦ sleep
        # await asyncio.sleep(0.01)

    def reset_failure_count(self, component: str):
        """Resets the failure count for a component upon success."""
        if component in self.failure_counts:
            logger.info(f"Component '{component}' recovered. Resetting failure count.")
            self.failure_counts[component] = 0
