import asyncio
import httpx  # [âœ… ä¿®å¤] é˜¶æ®µ 5 æ·»åŠ 
import os     # [âœ… ä¿®å¤] é˜¶æ®µ 5 æ·»åŠ 
from Phoenix_project.monitor.logging import get_logger

logger = get_logger(__name__)

class ErrorHandler:
    """
    Centralized error handling component.
    Responds to critical errors, manages retries, and can trigger
    system-wide safety mechanisms (like circuit breakers).
    """

    def __init__(self, config: dict):
        self.config = config.get("error_handler", {})
        self.max_retries = self.config.get("max_retries", 3)
        # [âœ… ä¿®å¤] é”®åä¸ system.yaml (Source 31) ä¸­çš„ "retry_delay_seconds" ä¿æŒä¸€è‡´
        self.retry_delay_base = self.config.get("retry_delay_seconds", 5) 
        
        # Track failures for specific components
        self.failure_counts = {}
        
        # --- [âœ… ä¿®å¤] é˜¶æ®µ 5 æ·»åŠ  ---
        self.slack_webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
        if not self.slack_webhook_url:
            logger.warning("ErrorHandler: SLACK_WEBHOOK_URL æœªè®¾ç½®ã€‚å°†è·³è¿‡ Slack è­¦æŠ¥ã€‚")
        # --- [ä¿®å¤ç»“æŸ] ---
        
        logger.info("ErrorHandler initialized.")

    async def handle_error(
        self,
        error: Exception,
        component: str,
        context: dict,
        # We need a way to trigger actions, e.g., via the orchestrator
        # or event distributor, passed during init.
        # For simplicity, we'll just log and suggest actions.
    ):
        """
        Main error handling entry point.
        
        Args:
            error (Exception): The exception that occurred.
            component (str): Name of the component that failed (e.g., "CognitiveEngine").
            context (dict): Context about what was happening (e.g., "decision_id").
        """
        
        decision_id = context.get("decision_id", "N/A")
        logger.error(
            f"Critical error in component '{component}' during cycle '{decision_id}': {error}",
            exc_info=True
        )
        
        # Update failure count
        self.failure_counts[component] = self.failure_counts.get(component, 0) + 1
        
        # --- Decision Logic ---
        
        # 1. Check for retries (if applicable to the error type)
        # This is complex; the *caller* usually manages its own retries.
        # This handler is more for *unrecoverable* errors.
        
        # 2. Check for circuit breaker
        if self.failure_counts[component] > self.max_retries:
            logger.critical(
                f"Component '{component}' has failed {self.failure_counts[component]} consecutive times. "
                "This may require a circuit breaker!"
            )
            # In a real system:
            # await self.risk_manager.trip_circuit_breaker(
            #     f"Component '{component}' failed repeatedly."
            # )
            
        # 3. Send notification (e.g., to Sentry, PagerDuty)
        await self.send_alert(error, component, context)
        
        # 4. Determine recovery strategy
        # For now, we just log. A real handler might try to
        # restart a component or switch to a fallback.
        
    async def send_alert(self, error: Exception, component: str, context: dict):
        """[âœ… ä¿®å¤] é˜¶æ®µ 5 ä¿®å¤ï¼šå‘é€è­¦æŠ¥åˆ° Slack (æ›¿æ¢å ä½ç¬¦)ã€‚"""
        alert_message = (
            f"ğŸ”¥ Phoenix Project ä¸¥é‡è­¦æŠ¥ ğŸ”¥\n"
            f"Component: {component}\n"
            f"Error: {str(error)}\n"
            f"Context: {str(context)}\n" # [ä¿®å¤] ç¡®ä¿ context è¢«åºåˆ—åŒ–ä¸º str
        )

        # ä»ç„¶åœ¨æœ¬åœ°æ—¥å¿—ä¸­è®°å½•
        logger.info(f"--- ALERT (Sending) ---\n{alert_message}")

        if not self.slack_webhook_url:
            # (å·²ç»åœ¨ __init__ ä¸­è­¦å‘Šè¿‡äº†, è¿™é‡Œå¯ä»¥å®‰é™è·³è¿‡)
            return

        payload = {"text": alert_message}
        try:
            # ä½¿ç”¨ httpx (å·²åœ¨ requirements.txt ä¸­) å¼‚æ­¥å‘é€
            async with httpx.AsyncClient() as client:
                response = await client.post(self.slack_webhook_url, json=payload)
                response.raise_for_status() # å¦‚æœæ˜¯ 4xx/5xx åˆ™æŠ›å‡ºå¼‚å¸¸
            logger.info("è­¦æŠ¥å·²æˆåŠŸå‘é€è‡³ Slackã€‚")
        except Exception as e:
            # å³ä½¿ Slack å‘é€å¤±è´¥ï¼Œä¹Ÿä¸åº”è®© ErrorHandler å´©æºƒ
            logger.error(f"å‘é€ Slack è­¦æŠ¥å¤±è´¥: {e}", exc_info=True)

        # [âœ… ä¿®å¤] ç§»é™¤æ—§çš„å ä½ç¬¦ sleep
        # await asyncio.sleep(0.01)

    def reset_failure_count(self, component: str):
        """Resets the failure count for a component upon success."""
        if component in self.failure_counts:
            logger.info(f"Component '{component}' recovered. Resetting failure count.")
            self.failure_counts[component] = 0
